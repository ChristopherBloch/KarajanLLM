{
  "commands": {
    "native": "auto",
    "nativeSkills": "auto"
  },
  "skills": {
    "load": {
      "extraDirs": ["/root/.openclaw/skills"]
    },
    "entries": {
      "aria-database": { "enabled": true },
      "aria-moltbook": { "enabled": true },
      "aria-goals": { "enabled": true },
      "aria-health": { "enabled": true }
    }
  },
  "gateway": {
    "port": 18789,
    "mode": "local",
    "bind": "lan",
    "trustedProxies": ["0.0.0.0/0", "::/0"],
    "controlUi": {
      "basePath": "/clawdbot",
      "allowInsecureAuth": true,
      "dangerouslyDisableDeviceAuth": true
    }
  },
  "ui": {
    "seamColor": "#3B82F6",
    "assistant": {
      "name": "Aria",
      "avatar": "⚡"
    }
  },
  "agents": {
    "defaults": {
      "maxConcurrent": 4,
      "workspace": "/root/.openclaw/workspace",
      "model": {
        "primary": "litellm/qwen3-local",
        "fallbacks": ["google/gemini-2.0-flash", "google/gemini-2.5-flash"]
      },
      "models": {
        "litellm/qwen3-local": { "alias": "Qwen3-VL 8B Local" },
        "google/gemini-2.0-flash": { "alias": "Gemini 2.0 Flash" },
        "google/gemini-2.5-flash": { "alias": "Gemini 2.5 Flash" }
      },
      "subagents": {
        "maxConcurrent": 8
      },
      "heartbeat": {
        "every": "30m",
        "target": "last",
        "prompt": "Read HEARTBEAT.md if it exists (workspace context). Follow it strictly. Do not infer or repeat old tasks from prior chats. If nothing needs attention, reply HEARTBEAT_OK."
      },
      "memorySearch": {
        "enabled": true,
        "provider": "openai",
        "fallback": "none"
      }
    },
    "list": [
      {
        "id": "main",
        "default": true,
        "identity": {
          "name": "Aria",
          "theme": "intelligent autonomous assistant with electric blue energy",
          "emoji": "⚡",
          "avatar": "⚡"
        }
      }
    ]
  },
  "tools": {
    "exec": {
      "backgroundMs": 10000,
      "timeoutSec": 1800,
      "cleanupMs": 1800000,
      "notifyOnExit": true
    }
  },
  "models": {
    "mode": "merge",
    "providers": {
      "litellm": {
        "baseUrl": "http://litellm:4000/v1",
        "apiKey": "sk-aria-local-key",
        "api": "openai-completions",
        "models": [
          {
            "id": "qwen3-local",
            "name": "Qwen3-VL 8B via LiteLLM",
            "reasoning": true,
            "input": ["text", "image"],
            "cost": { "input": 0, "output": 0, "cacheRead": 0, "cacheWrite": 0 },
            "contextWindow": 32768,
            "maxTokens": 8192
          }
        ]
      }
    }
  },
  "messages": {
    "ackReaction": "⚡",
    "ackReactionScope": "group-mentions",
    "responsePrefix": "[Aria]"
  }
}
